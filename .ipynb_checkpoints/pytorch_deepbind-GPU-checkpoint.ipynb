{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Research Example - DeepBind (2015)***\n",
    "# **Building the DeepBind model through a pytorch framework (GPU)**"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Preprocess**\n",
    "### 1.1. Load the raw data of ***ALX homeobox protein 1*** (SELEX sequencing data) \n",
    "- references \n",
    "    - http://tools.genes.toronto.edu/deepbind/D00289.002/index.html![image.png](attachment:image.png)\n",
    "    - https://github.com/MedChaabane/DeepBind-with-PyTorch\n",
    "- download \n",
    "    - [Training raw dataset](https://1drv.ms/u/s!AljTCh5CK9KvgYltlkAVHPv7kbdytg?e=qBtIgu) \n",
    "    - [Testing raw dataset](https://1drv.ms/u/s!AljTCh5CK9KvgYlsgGwcmTp5L-35iQ?e=k8eUxH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Alx1_DBD_TAAAGC20NCG_3_Z_B.seq finish (255508 lines, #positive: 127754, #negative: 127754)\n",
      "- sequence sizes : {20}\n",
      "Load Alx1_DBD_TAAAGC20NCG_3_Z_A.seq finish (128012 lines, #positive: 128012, #negative: 0)\n",
      "- sequence sizes : {20}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def raw_seq_parser(path):\n",
    "    f = open(path, \"r\")\n",
    "    seqs = []\n",
    "    seq_lens = []\n",
    "    labels = []\n",
    "    flines = f.readlines()\n",
    "    cols = None\n",
    "    for i, line in enumerate(flines):\n",
    "        if not i :\n",
    "            cols = line.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "        else:\n",
    "            fold_id, event_id, seq, bound = line.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "            seqs.append(seq)\n",
    "            labels.append(int(bound))\n",
    "            seq_lens.append(len(seq))\n",
    "            \n",
    "    num_pos = sum(labels)\n",
    "    num_neg = len(labels) - num_pos\n",
    "    print(\"Load {} finish ({} lines, #positive: {}, #negative: {})\".format(path, len(labels), num_pos, num_neg))\n",
    "    print(\"- sequence sizes : {}\".format(set(seq_lens)))\n",
    "    \n",
    "    return seqs, labels\n",
    "\n",
    "\n",
    "# path of raw data\n",
    "TRAIN_RAW = \"Alx1_DBD_TAAAGC20NCG_3_Z_B.seq\"\n",
    "TEST_RAW  = \"Alx1_DBD_TAAAGC20NCG_3_Z_A.seq\"\n",
    "    \n",
    "train_seqs, y = raw_seq_parser(TRAIN_RAW)\n",
    "test_seqs, test_y = raw_seq_parser(TEST_RAW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. DNA sequence encoding + padding for motif detector + reverse-complement mode\n",
    "\n",
    "- Baseline: one-hot encoding\n",
    "- Due to the length of all sequences in the dataset is same (20bp), we don't need the encoding methods for variable length data\n",
    "- **Padding the letter 'N' in front of an input sequence and the end too**\n",
    "- When training a model on sequences derived from double-stranded DNA (PBM, SELEX, ChIP-seq), it is unknown whether the protein bound to the input strand or whether it bound to the opposite strand.\n",
    "\n",
    "#### *(Supplimentary information in DeepBind 2015)*\n",
    "<img src=\"figures/deepbind_supp_01.PNG\" width=\"750px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding finished, with feature shape (511016, 38, 4)\n",
      "One-hot encoding finished, with feature shape (256024, 38, 4)\n"
     ]
    }
   ],
   "source": [
    "# ref [complement,reverse_complement] from [https://github.com/MedChaabane/DeepBind-with-PyTorch/]\n",
    "def complement(seq):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    complseq = [complement[base] for base in seq]\n",
    "    return complseq\n",
    "  \n",
    "def reverse_complement(seq):\n",
    "    seq = list(seq)\n",
    "    seq.reverse()\n",
    "    return ''.join(complement(seq))\n",
    "\n",
    "def onehot_encoder_with_padding_and_reverse_complement(seqs, labels, letters=\"ACGT\", motif_len=10):\n",
    "    enc = defaultdict(lambda: np.array([1/len(letters)]*len(letters))) # default. [0.25,0.25,0.25,0.25]\n",
    "    for i,l in enumerate(letters):\n",
    "        f      = np.zeros(len(letters))\n",
    "        f[i]   = 1\n",
    "        enc[l] = f\n",
    "    \n",
    "    # reverse-complement (note that it have to apply for DNA seqs)\n",
    "    _seqs = []\n",
    "    _labels = []\n",
    "    for seq, label in zip(seqs, labels):\n",
    "        _seqs.append(seq)\n",
    "        _labels.append([label])\n",
    "        _seqs.append(reverse_complement(seq))\n",
    "        _labels.append([label])\n",
    "    \n",
    "    seqs = _seqs\n",
    "    labels = _labels\n",
    "    \n",
    "    # one-hot encoding\n",
    "    onehot_features = []\n",
    "    for seq in seqs:\n",
    "        # Append padding letter 'N' accoding to the <length of motif-1>\n",
    "        seq = 'N' * (motif_len-1) + seq + 'N' * (motif_len-1)\n",
    "        feature = []\n",
    "        for c in seq.upper():\n",
    "            feature.append(enc[c])\n",
    "        onehot_features.append(feature)\n",
    "        \n",
    "    onehot_features = np.array(onehot_features)\n",
    "    print(\"One-hot encoding finished, with feature shape {}\".format(onehot_features.shape))\n",
    "    return onehot_features, labels\n",
    "    \n",
    "LEN_MOTIF      = 10\n",
    "X, y           = onehot_encoder_with_padding_and_reverse_complement(train_seqs, y, motif_len=LEN_MOTIF)\n",
    "test_x, test_y = onehot_encoder_with_padding_and_reverse_complement(test_seqs, test_y, motif_len=LEN_MOTIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Split Train & Valid dataset \n",
    "- The testset has only positive class\n",
    "- Most evaluation metrices of binary classification problem need negative class\n",
    "- We split the training set to train and valid datasets\n",
    "- The testset only used when the model training is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set | x: (342380, 38, 4), y: (342380, 1) \n",
      "Valid set | x: (168636, 38, 4), y: (168636, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = np.array(X), np.array(y) # convert python-list to numpy-array\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, \n",
    "                                                      test_size=0.33, # ratio of size of train-test set splitting\n",
    "                                                      random_state=42) # random-seed\n",
    "\n",
    "print(\"Train set | x: {}, y: {} \\nValid set | x: {}, y: {}\".format(train_x.shape,\n",
    "                                                                   train_y.shape,\n",
    "                                                                   valid_x.shape,\n",
    "                                                                   valid_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 4, 38) (5000, 4, 38) (1000, 4, 38)\n",
      "(50000, 1) (5000, 1) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x.reshape(-1, 4, 38)[:50000]\n",
    "valid_x = valid_x.reshape(-1, 4, 38)[:5000]\n",
    "test_x  = test_x.reshape(-1, 4, 38)[:1000]\n",
    "\n",
    "train_y = np.array(train_y[:50000])\n",
    "valid_y = np.array(valid_y[:5000])\n",
    "test_y  = np.array(test_y[:1000])\n",
    "\n",
    "print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "print(train_y.shape, valid_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 1D-Convolutional Neural Network for binary classification (pytorch)**\n",
    "### 2.1. Initialization of CNN-Model\n",
    "<img src=\"figures/deepbind_supp_02.PNG\" width=\"750px\">\n",
    "\n",
    "#### *Convolution*\n",
    "- The defining feature of any ConvNet is that it begins with at least one convolution stage. \n",
    "- In the context of genomic sequences, a 1-dimensional convolution over a 4-channel input can play the same role as a “motif scan” operation in a PWM or PSAM-based model.\n",
    "\n",
    "#### *Rectification*\n",
    "- We call this a rectified motif scan.\n",
    "- In neural network terminology, this simple nonlinear operation is known as a rectified linear unit (ReLU) layer\n",
    "\n",
    "#### *Pooling*\n",
    "- We implemented two choices for the pooling stage: **“max pooling”**, or **“max pooling and average pooling.”**\n",
    "\n",
    "#### *Neural network*\n",
    "- We allow the choice of either **“no hidden layer”** or **“one hidden layer with 32 rectified-linear units”** ...\n",
    "- In this example, only **“no hidden layer”** will be implemented.\n",
    "- Do not cover the dropout part of DeepBind too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Motif scanners : torch.Size([16, 4, 10])\n",
      "- Input shape    : torch.Size([10, 4, 38])\n",
      "- After 1d-conv  : torch.Size([10, 16, 29])\n",
      "- After max-pool : torch.Size([10, 32])\n",
      "- After fc-net   : torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_motifs, len_motif, pooling_type=\"max\"): # pool_type = [max, maxavg]\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.l_conv = nn.Conv1d(in_channels  = 4, \n",
    "                                out_channels = num_motifs,\n",
    "                                kernel_size  = len_motif,\n",
    "                                stride       = 1, \n",
    "                                padding      = 0)\n",
    "        \n",
    "        self.pooling_type = pooling_type\n",
    "        self.relu = nn.ReLU()\n",
    "        if pooling_type == \"max\":\n",
    "            self.l_nnet = nn.Linear(num_motifs,1) \n",
    "        else:\n",
    "            self.l_nnet = nn.Linear(num_motifs*2,1)\n",
    "            \n",
    "        print(\"- Motif scanners : {}\".format(self.l_conv.weight.size()))\n",
    "        \n",
    "    def get_motif_scanners(self):\n",
    "        return self.l_conv.weight\n",
    "    \n",
    "    def get_rectified_motif_scan(self, x):\n",
    "        x = self.l_conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_test(self, x):\n",
    "        print(\"- Input shape    : {}\".format(x.size()))\n",
    "        x = self.relu(self.l_conv(x))\n",
    "        print(\"- After 1d-conv  : {}\".format(x.size()))\n",
    "        m , _ = torch.max(x,dim=2)\n",
    "        if self.pooling_type == \"maxavg\":\n",
    "            a = torch.mean(x, dim=2)\n",
    "            x = torch.cat((m,a), dim=1)\n",
    "        else:\n",
    "            x = m\n",
    "        print(\"- After max-pool : {}\".format(x.size()))\n",
    "        logit = self.l_nnet(x)\n",
    "        y = torch.sigmoid(logit)\n",
    "        print(\"- After fc-net   : {}\".format(y.size()))\n",
    "        return y\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l_conv(x)\n",
    "        x = self.relu(x)\n",
    "        m , _ = torch.max(x,dim=2)\n",
    "        if self.pooling_type == \"maxavg\":\n",
    "            a = torch.mean(x, dim=2)\n",
    "            x = torch.cat((m,a), dim=1)\n",
    "        else:\n",
    "            x = m\n",
    "        logit = self.l_nnet(x)\n",
    "        y = torch.sigmoid(logit)\n",
    "        return y\n",
    "\n",
    "NUM_MOTIFS = 16\n",
    "convnet = ConvNet(num_motifs   = NUM_MOTIFS, \n",
    "                  len_motif    = LEN_MOTIF,\n",
    "                  pooling_type = \"maxavg\")\n",
    "output  = convnet.forward_test(torch.randn(10, 4, 38))  # (num_seq, num_in_chn, len_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Initialization of model trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCELoss()\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn import datasets, metrics\n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = optim.SGD(convnet.parameters(), lr=learning_rate)\n",
    "print(criterion)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 4, 38]) torch.Size([50000, 1])\n",
      "torch.Size([5000, 4, 38]) torch.Size([5000, 1])\n",
      "torch.Size([1000, 4, 38]) torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "# numpy array to tensor\n",
    "ts_train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "ts_train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "ts_valid_x = torch.tensor(valid_x, dtype=torch.float32)\n",
    "ts_valid_y = torch.tensor(valid_y, dtype=torch.float32)\n",
    "ts_test_x  = torch.tensor(test_x, dtype=torch.float32)\n",
    "ts_test_y  = torch.tensor(test_y, dtype=torch.float32)\n",
    "print(ts_train_x.size(), ts_train_y.size())\n",
    "print(ts_valid_x.size(), ts_valid_y.size())\n",
    "print(ts_test_x.size(), ts_test_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(_x,_y) for _x, _y in zip(ts_train_x, ts_train_y)]\n",
    "valid_data = [(_x,_y) for _x, _y in zip(ts_valid_x, ts_valid_y)]\n",
    "test_data  = [(_x,_y) for _x, _y in zip(ts_test_x, ts_test_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset    = train_data, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle    = True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset    = valid_data,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle    = True)\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(dataset    = test_data,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle    = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (l_conv): Conv1d(4, 16, kernel_size=(10,), stride=(1,))\n",
       "  (relu): ReLU()\n",
       "  (l_nnet): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch      0 | Train Loss 0.69081 | Valid Loss 0.68895 | Valid ROC-AUC 0.63469\n",
      "Epoch     10 | Train Loss 0.58425 | Valid Loss 0.58786 | Valid ROC-AUC 0.75967\n",
      "Epoch     20 | Train Loss 0.52788 | Valid Loss 0.53807 | Valid ROC-AUC 0.80083\n",
      "Epoch     30 | Train Loss 0.50272 | Valid Loss 0.51541 | Valid ROC-AUC 0.82053\n",
      "Epoch     40 | Train Loss 0.48326 | Valid Loss 0.49723 | Valid ROC-AUC 0.83616\n",
      "Epoch     50 | Train Loss 0.46361 | Valid Loss 0.48063 | Valid ROC-AUC 0.85059\n",
      "Epoch     60 | Train Loss 0.44863 | Valid Loss 0.46676 | Valid ROC-AUC 0.85902\n",
      "Epoch     70 | Train Loss 0.43958 | Valid Loss 0.46279 | Valid ROC-AUC 0.86297\n",
      "Epoch     80 | Train Loss 0.43433 | Valid Loss 0.45891 | Valid ROC-AUC 0.86479\n",
      "Epoch     90 | Train Loss 0.43083 | Valid Loss 0.45653 | Valid ROC-AUC 0.86555\n",
      "Epoch    100 | Train Loss 0.42862 | Valid Loss 0.45566 | Valid ROC-AUC 0.86635\n",
      "Epoch    110 | Train Loss 0.42671 | Valid Loss 0.45582 | Valid ROC-AUC 0.86696\n",
      "Epoch    120 | Train Loss 0.42539 | Valid Loss 0.45386 | Valid ROC-AUC 0.86769\n",
      "Epoch    130 | Train Loss 0.42377 | Valid Loss 0.45261 | Valid ROC-AUC 0.86866\n",
      "Epoch    140 | Train Loss 0.42210 | Valid Loss 0.45140 | Valid ROC-AUC 0.86950\n",
      "Epoch    150 | Train Loss 0.42112 | Valid Loss 0.45047 | Valid ROC-AUC 0.86996\n",
      "Epoch    160 | Train Loss 0.42006 | Valid Loss 0.44957 | Valid ROC-AUC 0.87057\n",
      "Epoch    170 | Train Loss 0.41879 | Valid Loss 0.44905 | Valid ROC-AUC 0.87101\n",
      "Epoch    180 | Train Loss 0.41799 | Valid Loss 0.44845 | Valid ROC-AUC 0.87141\n",
      "Epoch    190 | Train Loss 0.41714 | Valid Loss 0.44763 | Valid ROC-AUC 0.87187\n",
      "Epoch    200 | Train Loss 0.41633 | Valid Loss 0.44705 | Valid ROC-AUC 0.87254\n",
      "Epoch    210 | Train Loss 0.41535 | Valid Loss 0.44607 | Valid ROC-AUC 0.87307\n",
      "Epoch    220 | Train Loss 0.41465 | Valid Loss 0.44796 | Valid ROC-AUC 0.87360\n",
      "Epoch    230 | Train Loss 0.41361 | Valid Loss 0.44462 | Valid ROC-AUC 0.87420\n",
      "Epoch    240 | Train Loss 0.41262 | Valid Loss 0.44587 | Valid ROC-AUC 0.87491\n",
      "Epoch    250 | Train Loss 0.41142 | Valid Loss 0.44172 | Valid ROC-AUC 0.87579\n",
      "Epoch    260 | Train Loss 0.41050 | Valid Loss 0.44026 | Valid ROC-AUC 0.87662\n",
      "Epoch    270 | Train Loss 0.40916 | Valid Loss 0.43877 | Valid ROC-AUC 0.87753\n",
      "Epoch    280 | Train Loss 0.40824 | Valid Loss 0.44072 | Valid ROC-AUC 0.87831\n",
      "Epoch    290 | Train Loss 0.40722 | Valid Loss 0.44082 | Valid ROC-AUC 0.87899\n",
      "Epoch    300 | Train Loss 0.40613 | Valid Loss 0.43646 | Valid ROC-AUC 0.87982\n",
      "Epoch    310 | Train Loss 0.40546 | Valid Loss 0.43418 | Valid ROC-AUC 0.88045\n",
      "Epoch    320 | Train Loss 0.40463 | Valid Loss 0.43329 | Valid ROC-AUC 0.88101\n",
      "Epoch    330 | Train Loss 0.40396 | Valid Loss 0.43271 | Valid ROC-AUC 0.88168\n",
      "Epoch    340 | Train Loss 0.40338 | Valid Loss 0.43158 | Valid ROC-AUC 0.88209\n",
      "Epoch    350 | Train Loss 0.40262 | Valid Loss 0.43074 | Valid ROC-AUC 0.88266\n",
      "Epoch    360 | Train Loss 0.40183 | Valid Loss 0.43045 | Valid ROC-AUC 0.88334\n",
      "Epoch    370 | Train Loss 0.40126 | Valid Loss 0.42942 | Valid ROC-AUC 0.88376\n",
      "Epoch    380 | Train Loss 0.40070 | Valid Loss 0.42868 | Valid ROC-AUC 0.88430\n",
      "Epoch    390 | Train Loss 0.40017 | Valid Loss 0.42804 | Valid ROC-AUC 0.88453\n",
      "Epoch    400 | Train Loss 0.39968 | Valid Loss 0.42707 | Valid ROC-AUC 0.88488\n",
      "Epoch    410 | Train Loss 0.39930 | Valid Loss 0.42770 | Valid ROC-AUC 0.88496\n",
      "Epoch    420 | Train Loss 0.39889 | Valid Loss 0.42662 | Valid ROC-AUC 0.88515\n",
      "Epoch    430 | Train Loss 0.39832 | Valid Loss 0.42644 | Valid ROC-AUC 0.88513\n",
      "Epoch    440 | Train Loss 0.39804 | Valid Loss 0.42710 | Valid ROC-AUC 0.88526\n",
      "Epoch    450 | Train Loss 0.39751 | Valid Loss 0.43021 | Valid ROC-AUC 0.88589\n",
      "Epoch    460 | Train Loss 0.39687 | Valid Loss 0.42410 | Valid ROC-AUC 0.88644\n",
      "Epoch    470 | Train Loss 0.39650 | Valid Loss 0.42427 | Valid ROC-AUC 0.88663\n",
      "Epoch    480 | Train Loss 0.39605 | Valid Loss 0.42802 | Valid ROC-AUC 0.88659\n",
      "Epoch    490 | Train Loss 0.39571 | Valid Loss 0.42564 | Valid ROC-AUC 0.88677\n"
     ]
    }
   ],
   "source": [
    "convnet.train()\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    train_loss = []\n",
    "    for index, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = convnet(data)\n",
    "        loss   = criterion(output, target)\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    # Validation\n",
    "    valid_output = convnet(ts_valid_x.to(device))\n",
    "    valid_loss = criterion(valid_output.to(device), ts_valid_y.to(device))\n",
    "    valid_loss = valid_loss.item()\n",
    "    valid_roc_auc = metrics.roc_auc_score(ts_valid_y.cpu().detach().numpy(),\n",
    "                                          valid_output.cpu().detach().numpy())\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch {:>6} | Train Loss {:.5f} | Valid Loss {:.5f} | Valid ROC-AUC {:.5f}\".format(epoch, \n",
    "                                                                                              np.mean(train_loss),\n",
    "                                                                                              valid_loss, \n",
    "                                                                                              valid_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.81      0.89      1000\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.50      0.40      0.45      1000\n",
      "weighted avg       1.00      0.81      0.89      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_output = convnet(ts_test_x.to(device)).cpu().detach().numpy()\n",
    "test_output = test_output > 0.5\n",
    "print(metrics.classification_report(test_y, test_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Visualizations for DeepBind models**\n",
    "### 3.1. Mutation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Sequence Logos\n",
    "To visualize the pattern learned by a particular DeepBind motif detector $𝑀_𝑘$, we generate a PWM derived from the detector’s response to actual sequences.\n",
    "\n",
    "1. We feed all sequences from the test set (foreground and background) through the convolutional and rectification stages of the DeepBind model\n",
    "2. We align all the sequences that passed the activation threshold\n",
    "3. Once the sequences are aligned, we generate a position frequency matrix (PFM)\n",
    "4. Transform it into a sequence logo in the standard way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ConvNet(\n",
      "  (l_conv): Conv1d(4, 16, kernel_size=(10,), stride=(1,))\n",
      "  (relu): ReLU()\n",
      "  (l_nnet): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "Test input sequences for extracting motif torch.Size([1000, 4, 38])\n",
      "Returned rectified motif scan data (1000, 16, 29)\n"
     ]
    }
   ],
   "source": [
    "# < Position Frequency Matrix using DeepBind model >\n",
    "# \n",
    "# 1. Get rectified motif scan result (from model) from the test dataset sequences\n",
    "# 2. For each motif, find maximum valued position (j)\n",
    "# 3. Extract subsequence from input sequence where (j-m+1) ~ (j)\n",
    "# 3-1 when the positions (j-m+1) ~ (j) beyond the sequence range, fill the empty (letter N)\n",
    "# 4. Accumulate all subsequences (length m) and count letter of each position\n",
    "\n",
    "def get_subsequence(seq_x, start, end, letters=\"ACGT\"):\n",
    "    ret = \"\"\n",
    "    ldict = {i:l for i,l in enumerate(letters)}\n",
    "    if start < 0:\n",
    "        ret = \"N\"*(-start) + ret\n",
    "        for i in range(end):\n",
    "            x = seq_x[:, i]\n",
    "            base = ldict[np.argmax(x)]\n",
    "            ret = ret + base\n",
    "    else:\n",
    "        for i in range(start, end):\n",
    "            x = seq_x[:, i]\n",
    "            base = ldict[np.argmax(x)]\n",
    "            ret = ret + base\n",
    "    \n",
    "    return ret\n",
    "\n",
    "# Check the global parameters\n",
    "print(LEN_MOTIF, convnet)\n",
    "print(\"Test input sequences for extracting motif {}\".format(ts_test_x.shape))\n",
    "\n",
    "# 1. Get rectified motif scan result (from model) from the test dataset sequences\n",
    "rect_scans = convnet.get_rectified_motif_scan(ts_test_x.to(device)).cpu().detach().numpy() \n",
    "print(\"Returned rectified motif scan data {}\".format(rect_scans.shape))\n",
    "\n",
    "# 4. Accumulate all subsequences (length m) and count letter of each position\n",
    "test_subseqs_list = defaultdict(lambda: [])\n",
    "\n",
    "for test_seq, rect_scan in zip(ts_test_x, rect_scans):    \n",
    "    test_seq = test_seq.detach().numpy()\n",
    "    \n",
    "    for m_i, m_scans in enumerate(rect_scan):\n",
    "        # 2. For each motif, find maximum valued position (j)\n",
    "        j = np.argmax(m_scans)\n",
    "        j_m_1 = j - LEN_MOTIF + 1\n",
    "        \n",
    "        # 3. Extract subsequence from input sequence where (j-m+1) ~ (j)\n",
    "        # 3-1 when the positions (j-m+1) ~ (j) beyond the sequence range, fill the empty (letter N)\n",
    "        subseq = get_subsequence(test_seq, j_m_1, j+1)\n",
    "        \n",
    "        # print(m_i+1, j_m_1, j, subseq, len(subseq))\n",
    "        test_subseqs_list[m_i].append(subseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_subseqs_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAACACGAAA',\n",
       " 'AAACAAGCAA',\n",
       " 'ACACAGCAAA',\n",
       " 'CGACAAAGAA',\n",
       " 'CACAACGAAA',\n",
       " 'AACAAAGCAA',\n",
       " 'NNNNCACAAA',\n",
       " 'NNNNNNNAAA',\n",
       " 'AAACAAGACA',\n",
       " 'AAACAAGACA',\n",
       " 'CGAAAGCAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'ACAAAAGCAA',\n",
       " 'AAACAAGCAA',\n",
       " 'AACAAACAAA',\n",
       " 'CACAAACAAA',\n",
       " 'CAACAAAACA',\n",
       " 'NNNNNNNCAA',\n",
       " 'AACAACGAAA',\n",
       " 'AACAACGAAA',\n",
       " 'NNNACAGCAA',\n",
       " 'AAACAAGCAA',\n",
       " 'NNCAACGAAA',\n",
       " 'GCAAGAAACA',\n",
       " 'CAACAAGCAA',\n",
       " 'NNNTACGAAA',\n",
       " 'GAACGAAAAC',\n",
       " 'NNNNNNNGCA',\n",
       " 'CAACAAAACA',\n",
       " 'AACAAAGCAA',\n",
       " 'AGAGCAAACC',\n",
       " 'NNNNNNNCTA',\n",
       " 'AAACAACGAA',\n",
       " 'NNNNNGCAAC',\n",
       " 'ACAAACGAAA',\n",
       " 'CAACACAAAA',\n",
       " 'AAACCGGAAA',\n",
       " 'NNNNNNNCAA',\n",
       " 'NNNNNNNTCA',\n",
       " 'NNNNGAAAAC',\n",
       " 'CAACAACAAC',\n",
       " 'AAAACAGACA',\n",
       " 'NNNNNNNAAA',\n",
       " 'AGCAACAGAC',\n",
       " 'CAAACCAAAA',\n",
       " 'CCAAAAGCAA',\n",
       " 'NNNNGCACAA',\n",
       " 'NNNNNNNAAA',\n",
       " 'AACAAAGACA',\n",
       " 'NNNACAGACA',\n",
       " 'CCAGAAAACA',\n",
       " 'NNNNNNNAAA',\n",
       " 'NNNCAAGACC',\n",
       " 'ACAAAAGCAA',\n",
       " 'NNNNNNNCTA',\n",
       " 'AAACAAGACA',\n",
       " 'NNNAAACAAA',\n",
       " 'AACAAAGACA',\n",
       " 'AAAACCGAAA',\n",
       " 'AGCAAAGCAA',\n",
       " 'CAAAACCGAA',\n",
       " 'NNNNNNNGCA',\n",
       " 'ACAAACCAAA',\n",
       " 'NNCTACGACA',\n",
       " 'AAACAAACAC',\n",
       " 'ACAGACCGAA',\n",
       " 'NNNNGCCAAA',\n",
       " 'GCAAGCAACA',\n",
       " 'GCAAAGCGAA',\n",
       " 'AACAAACGAA',\n",
       " 'AGCAAAGCAA',\n",
       " 'NNNGAAACAA',\n",
       " 'CACAAACAAA',\n",
       " 'ACAAAACAAA',\n",
       " 'AAACACGAAA',\n",
       " 'GAAACCGAAA',\n",
       " 'CCGAAAGACA',\n",
       " 'AAAACAGACA',\n",
       " 'TAACAAGACA',\n",
       " 'CAACAAGCAA',\n",
       " 'CAACAACAAA',\n",
       " 'TAACAACAAA',\n",
       " 'AAACAAGACA',\n",
       " 'NNNACACAAA',\n",
       " 'CGAAGAACGC',\n",
       " 'AACAACGAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'AACGACAAAA',\n",
       " 'TACAAAGACA',\n",
       " 'AACAAAGCAA',\n",
       " 'CAAAGCAAAC',\n",
       " 'GCCAAGCAAA',\n",
       " 'CAAACACAAA',\n",
       " 'AAGCAACAAA',\n",
       " 'GAAACACGAA',\n",
       " 'CACAACGAAA',\n",
       " 'NNNACCGAAA',\n",
       " 'AAGCAAGACA',\n",
       " 'NNNNNNNACC',\n",
       " 'AACGACAAAA',\n",
       " 'GCAAAAGACA',\n",
       " 'ACAAAAGCAA',\n",
       " 'AACAAAGCAA',\n",
       " 'CAACAACAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'NNNNGCAAAC',\n",
       " 'AACAAAGACA',\n",
       " 'AAACAAGCAA',\n",
       " 'AAACAAGCAA',\n",
       " 'CAACAAGCAA',\n",
       " 'NNNCTCGAAA',\n",
       " 'AGAACCGAAA',\n",
       " 'NNNNGAAACA',\n",
       " 'NNNNNNNATC',\n",
       " 'NNNNNNCGAA',\n",
       " 'NNNNNAAGAA',\n",
       " 'NNCAAAGCAA',\n",
       " 'GCCAGACAAA',\n",
       " 'ACGAAGCAAC',\n",
       " 'ACGAAGCAAC',\n",
       " 'GCAGAAAACG',\n",
       " 'CAAACAGAAC',\n",
       " 'CCAAAACAAA',\n",
       " 'ACAAAACAAC',\n",
       " 'GCAAGAAACA',\n",
       " 'ACGAGAACAA',\n",
       " 'AACAAAGACA',\n",
       " 'CAAACAGCAA',\n",
       " 'AAAACAGCAA',\n",
       " 'ACAAAAGCAA',\n",
       " 'NNNNTGAAAC',\n",
       " 'NNNNNNNATA',\n",
       " 'ACAGAAAACA',\n",
       " 'GTCAGAAAAC',\n",
       " 'CAACACAAAA',\n",
       " 'AGAACAAACA',\n",
       " 'NNNNNNNCTA',\n",
       " 'AGAACCAAAA',\n",
       " 'NNGCCAAAAC',\n",
       " 'NNNNNNNACA',\n",
       " 'GAAACAGACC',\n",
       " 'AAACAAGACA',\n",
       " 'AAACAACAAA',\n",
       " 'AAACAAGACA',\n",
       " 'AGACAACAAA',\n",
       " 'NNNNNNNCAA',\n",
       " 'AACAAAGACA',\n",
       " 'AACAACGAAA',\n",
       " 'NNNCAACAAA',\n",
       " 'AAACAAGCAA',\n",
       " 'GAAGCAAACC',\n",
       " 'GACAGAAACA',\n",
       " 'AGCAAACAAA',\n",
       " 'NNNCAACAAA',\n",
       " 'ACAAACGAAA',\n",
       " 'NNACAGCAAC',\n",
       " 'NNNNNNGAAC',\n",
       " 'NNNNNNNATA',\n",
       " 'NNNCAAGACA',\n",
       " 'CCAAAACAAA',\n",
       " 'NNNNNNNTAA',\n",
       " 'NNNNGTCAAA',\n",
       " 'ACAAAACAAA',\n",
       " 'ACAAAACAAA',\n",
       " 'CCAGACAAAA',\n",
       " 'CCGAAACAAA',\n",
       " 'AGACAGACCA',\n",
       " 'CGACAAGCAA',\n",
       " 'NNNNNNNATA',\n",
       " 'GCAACAGAAC',\n",
       " 'CCAAACGAAA',\n",
       " 'CACAAACAAA',\n",
       " 'ACAAAAGACA',\n",
       " 'AAGCAAGACA',\n",
       " 'AGCAAAGACA',\n",
       " 'AAAACACAAC',\n",
       " 'GAAGCAACAA',\n",
       " 'NNNNNNNNNA',\n",
       " 'NNNNNNNATA',\n",
       " 'NNNTACGGAA',\n",
       " 'NNNACCGAAA',\n",
       " 'AAAACACAAC',\n",
       " 'AAAACCGAAA',\n",
       " 'CAAACCGAAA',\n",
       " 'AACAAAGACA',\n",
       " 'AAACAAGACA',\n",
       " 'NNNNNNNTAA',\n",
       " 'GAGAACAAAA',\n",
       " 'NNNAACGAAA',\n",
       " 'AGAACAGCAA',\n",
       " 'AAACAACAAA',\n",
       " 'AACAAAGCAA',\n",
       " 'AGCAAAGACC',\n",
       " 'AAAACAGACA',\n",
       " 'NNNNNNGAAC',\n",
       " 'ACAGCGCAAA',\n",
       " 'NNNATAGCGA',\n",
       " 'AAACACGAAA',\n",
       " 'ACAAAACAAA',\n",
       " 'AAACAAGACA',\n",
       " 'NNNNNNNATA',\n",
       " 'GTAACAACAA',\n",
       " 'GACAGAAACA',\n",
       " 'AACAACAGAA',\n",
       " 'GCAAAAGACA',\n",
       " 'AAGCAAGACA',\n",
       " 'CCAAACGAAA',\n",
       " 'AGCAAAGACA',\n",
       " 'NNNACCGAAA',\n",
       " 'CACAAAGCAA',\n",
       " 'NNNNNNGCCA',\n",
       " 'GAAACAAGCA',\n",
       " 'AACAAAGACA',\n",
       " 'ACAAAACAAC',\n",
       " 'GCCAAAAGAC',\n",
       " 'AGCAACGAAC',\n",
       " 'AACACGAACA',\n",
       " 'NNNNNNNATA',\n",
       " 'NNNCTCGAAA',\n",
       " 'ACAAACGAAA',\n",
       " 'TCGAACCAAA',\n",
       " 'NNNNAACGAA',\n",
       " 'NNNNNCGCAA',\n",
       " 'GAAAGACAAA',\n",
       " 'NNNNGCCAAA',\n",
       " 'ACGAAACAAA',\n",
       " 'NNNNNNNAAC',\n",
       " 'GAAGCAACAA',\n",
       " 'AAAACAGCAA',\n",
       " 'NNNATAGACA',\n",
       " 'NNNNNNNCAA',\n",
       " 'GCAACAACAA',\n",
       " 'CAACACAAAC',\n",
       " 'AAAACCGAAA',\n",
       " 'AAGACCGAAA',\n",
       " 'ACAAGAAACA',\n",
       " 'ACGAACGGAA',\n",
       " 'CCAAACGGAA',\n",
       " 'CGAACAAGAC',\n",
       " 'NNNNNNNAAA',\n",
       " 'AAACAACAAA',\n",
       " 'AAAACCGAAA',\n",
       " 'NNNNNNCAAC',\n",
       " 'NNNNNNNACA',\n",
       " 'AAAGCAAACA',\n",
       " 'NNNNNNNATA',\n",
       " 'GACAAGACAA',\n",
       " 'AACAAGCACG',\n",
       " 'NNNCAAGACA',\n",
       " 'AAAACAGCAA',\n",
       " 'NNNNNNNACA',\n",
       " 'CAACACGAAA',\n",
       " 'AAACAAGCAC',\n",
       " 'CGACAACAAA',\n",
       " 'AACAACGAAA',\n",
       " 'AAACACGAAA',\n",
       " 'NNNAAACAAA',\n",
       " 'ACAAAAGACA',\n",
       " 'ACAAAAGCAA',\n",
       " 'NNNNNGCAAC',\n",
       " 'GAACAAGACA',\n",
       " 'NNNACCGAAA',\n",
       " 'CAAACACAAA',\n",
       " 'NNNCAAGCAA',\n",
       " 'CACAACGAAA',\n",
       " 'AACAAAGCAA',\n",
       " 'CAAACAGACA',\n",
       " 'NNNATAGCAA',\n",
       " 'NNNNNNNATA',\n",
       " 'NNNNNNGTAA',\n",
       " 'NNNCAAGACA',\n",
       " 'CAACAACAAA',\n",
       " 'GAAACACAAA',\n",
       " 'TAAACAGCAA',\n",
       " 'CAACAACGAA',\n",
       " 'CAACAAGACA',\n",
       " 'NNACAGCAAC',\n",
       " 'NNNNNNNNCA',\n",
       " 'GCAAACAGAA',\n",
       " 'GACAACAAAC',\n",
       " 'NNNNNNNATA',\n",
       " 'AGCAACAAGA',\n",
       " 'CAACAAGACA',\n",
       " 'NNNAAAGCAA',\n",
       " 'ACAAAACAAA',\n",
       " 'TACAACGAAA',\n",
       " 'CAACAACAAA',\n",
       " 'AAAACAGCAA',\n",
       " 'NNNNNNNACC',\n",
       " 'ACAGAAACAA',\n",
       " 'AAAACAGCAA',\n",
       " 'NNNTCCGAAA',\n",
       " 'NNNNNNNAAA',\n",
       " 'CCAAAAGCAA',\n",
       " 'CAAGAAGCAC',\n",
       " 'ATGAGCCAAA',\n",
       " 'TCAAAAGACA',\n",
       " 'AAACAAGACC',\n",
       " 'NNNATACAAA',\n",
       " 'AAACAAGCAA',\n",
       " 'NNNNNNGCCA',\n",
       " 'GGAAACAAAA',\n",
       " 'CCAAAAGACA',\n",
       " 'CAAACAGCAA',\n",
       " 'CGGAACGAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'ACGAAAGCCA',\n",
       " 'CCAAAAGCAA',\n",
       " 'CAAGCACAAC',\n",
       " 'NNNNNNNACA',\n",
       " 'CGAGCCAAAC',\n",
       " 'NNNTACGAAA',\n",
       " 'CAGCAACGAA',\n",
       " 'CAACACGAAA',\n",
       " 'NNNNNNNAGA',\n",
       " 'GCAACAACAA',\n",
       " 'ACAAGCAAAA',\n",
       " 'NNNNNNNATA',\n",
       " 'NNNGTACAAA',\n",
       " 'ACAAAAGACA',\n",
       " 'ACAGAACAAC',\n",
       " 'NNNNNNNAAA',\n",
       " 'AACAACAACG',\n",
       " 'NNNNNNNCAA',\n",
       " 'AACAAAGCAA',\n",
       " 'AGAACAGACA',\n",
       " 'AAACAACAAA',\n",
       " 'AAAACAGCAA',\n",
       " 'AACAAAGCAA',\n",
       " 'ACAAACGAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'GAAACAAAAC',\n",
       " 'NNNCAACAAC',\n",
       " 'CAAACAGACA',\n",
       " 'NNNNGCCAAA',\n",
       " 'AAGCGAACAA',\n",
       " 'CCAGACAAAA',\n",
       " 'ACACAACGAA',\n",
       " 'CGACACGAAA',\n",
       " 'AACAAACAAA',\n",
       " 'AAACAAGACA',\n",
       " 'AAAACAGCAA',\n",
       " 'NNNNNNNCAA',\n",
       " 'CAGACCGAAC',\n",
       " 'NNNNNNNCAA',\n",
       " 'NCAAAACAGC',\n",
       " 'AAAACACAAA',\n",
       " 'NNNCTCGAAA',\n",
       " 'CCAAACGAAA',\n",
       " 'AAGACGAACA',\n",
       " 'NNNAAAGACA',\n",
       " 'ACGAAACAAA',\n",
       " 'CCGAAGAACC',\n",
       " 'AAAACAGACC',\n",
       " 'NNNTACGAAA',\n",
       " 'AAACAAGACA',\n",
       " 'CGAACCGAAC',\n",
       " 'NNNGTCAAAA',\n",
       " 'AGAGCAAACC',\n",
       " 'NNNNNNNATA',\n",
       " 'NNNNGAAAAC',\n",
       " 'NNNNNNNTCA',\n",
       " 'NNNNNNNATA',\n",
       " 'TAAACAGCAA',\n",
       " 'CAAACAGACA',\n",
       " 'CAACAACAAA',\n",
       " 'AACAAACAAA',\n",
       " 'CCAAAAGCAA',\n",
       " 'NNNNNNNTAA',\n",
       " 'CCAAACAAAA',\n",
       " 'CAACGCAAAA',\n",
       " 'ACGGAAAACA',\n",
       " 'ACAAGAAACC',\n",
       " 'ACAGAAAACA',\n",
       " 'AAACACGAAA',\n",
       " 'NNNNNNNATA',\n",
       " 'ACAAACGAAA',\n",
       " 'NNNACACAAC',\n",
       " 'NNNNNNNATA',\n",
       " 'CGACACAAAA',\n",
       " 'ACGAACAAAC',\n",
       " 'ATCAAAAGCA',\n",
       " 'NNNAAAGACA',\n",
       " 'AAACAACAAA',\n",
       " 'NNNNNNGCCA',\n",
       " 'AAAGCCAAAC',\n",
       " 'CAAACAGCAA',\n",
       " 'NNNNNNNNNC',\n",
       " 'AACAGCAACA',\n",
       " 'AAACAACACA',\n",
       " 'AACAACGAAA',\n",
       " 'TCAAAAGACA',\n",
       " 'NNNCACGAAA',\n",
       " 'AAACAAGACA',\n",
       " 'CACAAACAAA',\n",
       " 'CCAAAAGACA',\n",
       " 'NNNNNNNGAA',\n",
       " 'NGCAACGCAA',\n",
       " 'AGCAAAGACA',\n",
       " 'CAGACAAAGC',\n",
       " 'CACAAAGCAA',\n",
       " 'AAAACACAAA',\n",
       " 'AACAACGAAA',\n",
       " 'AGACAACAAA',\n",
       " 'NNNTGACAAA',\n",
       " 'CAGCAGCAAA',\n",
       " 'CCGGACAAAA',\n",
       " 'NNNNNNNATA',\n",
       " 'NNNATAGACA',\n",
       " 'NNNTAAGACC',\n",
       " 'TCAGAAAACA',\n",
       " 'AGAACAGACA',\n",
       " 'CGAAGAACAA',\n",
       " 'TAGACGAACA',\n",
       " 'NNNNNNCAAA',\n",
       " 'AAAGCAAGAA',\n",
       " 'GCAAAAGACA',\n",
       " 'AAGACACAAA',\n",
       " 'NNNAAAGCAA',\n",
       " 'AGACACGAAA',\n",
       " 'CAAACGAACA',\n",
       " 'AGCAAGAAAC',\n",
       " 'AACAAACAAC',\n",
       " 'ACGAGAAACA',\n",
       " 'NNNCAAGACA',\n",
       " 'AACAAACAAA',\n",
       " 'AACGAAAACA',\n",
       " 'NNNGAAAACC',\n",
       " 'CACAACGAAA',\n",
       " 'CAACAACAAA',\n",
       " 'AAACAACAAA',\n",
       " 'CAACAAGACA',\n",
       " 'AACAAAGACA',\n",
       " 'AAACAAGCAA',\n",
       " 'AACAAACCAA',\n",
       " 'ACGAAACAGC',\n",
       " 'ACAAAACAAA',\n",
       " 'CGAACCGAAA',\n",
       " 'ACAGAAAACA',\n",
       " 'CAGACCGAAA',\n",
       " 'CCAGACAAAA',\n",
       " 'GAACGACAAC',\n",
       " 'NNNNGCCAAA',\n",
       " 'GCAACAAAGC',\n",
       " 'AAACCGGACA',\n",
       " 'ACGACACGAA',\n",
       " 'ACAAAAGACA',\n",
       " 'CCAAAAGCAA',\n",
       " 'AACGAAAACA',\n",
       " 'NNNNNNNAAA',\n",
       " 'AAAACCGAAA',\n",
       " 'AAGACACGAA',\n",
       " 'CAAGACAGAC',\n",
       " 'ACAAGGCAAA',\n",
       " 'NGAAAACAGA',\n",
       " 'NNNNNNNACA',\n",
       " 'CAAACAGCAA',\n",
       " 'TACAACGAAA',\n",
       " 'NNNNNNNAAA',\n",
       " 'TCAAAAGCAA',\n",
       " 'AAACAAGCAA',\n",
       " 'ACAAAAGACA',\n",
       " 'CAGCAAAGCA',\n",
       " 'NNNNNNNACA',\n",
       " 'NNNATACAAA',\n",
       " 'AACAAACAAA',\n",
       " 'NNNNNNNAAA',\n",
       " 'NNCTAAACGA',\n",
       " 'NNNCAACAAA',\n",
       " 'AACAAAGCAA',\n",
       " 'CCGAACGAAA',\n",
       " 'NNNTCACAAC',\n",
       " 'AAGACACAAA',\n",
       " 'NNNNNNNGCA',\n",
       " 'GACAAACAAA',\n",
       " 'AAACAAGACA',\n",
       " 'ACAAAAGACC',\n",
       " 'AAACACGAAA',\n",
       " 'NNNNNNNCTC',\n",
       " 'NNNAAAGCAA',\n",
       " 'AAAACCGAAA',\n",
       " 'CCAAAACAAA',\n",
       " 'AACCGAGAAC',\n",
       " 'NNNNNNNAAA',\n",
       " 'NNNNNNNCTA',\n",
       " 'NNNNGACAAA',\n",
       " 'NNNTAAGACA',\n",
       " 'CGACAAGCAA',\n",
       " 'NNNAACGAAA',\n",
       " 'AAACAAGCAA',\n",
       " 'NNNCTACGAA',\n",
       " 'AACAAAGACA',\n",
       " 'ACGGAAAACC',\n",
       " 'NNNCTGCAAA',\n",
       " 'CCAAAAGACA',\n",
       " 'AAACACGAAA',\n",
       " 'ACAGAAAACA',\n",
       " 'ACAAAAGACA',\n",
       " 'AACAGCGACA',\n",
       " 'NNNNNNNCTA',\n",
       " 'TACAAAGACC',\n",
       " 'AAAACAGACA',\n",
       " 'NNNTAACAAA',\n",
       " 'ACAAAAGCAA',\n",
       " 'TCAGAAAACA',\n",
       " 'CAGCAAAACA',\n",
       " 'GCAGACGCAA',\n",
       " 'CAAAGCGACA',\n",
       " 'NNNNNNNAAA',\n",
       " 'NNNNGCAAAC',\n",
       " 'AAACAAGACA',\n",
       " 'ACAAAAGCAA',\n",
       " 'AAAACCGAAA',\n",
       " 'AAACAAGACA',\n",
       " 'NNNTACGAAA',\n",
       " 'AAACAAGCAA',\n",
       " 'AAACAACAAA',\n",
       " 'CCAAAAGACA',\n",
       " 'ACAGAAAACA',\n",
       " 'NNNNNNNACA',\n",
       " 'AACAAAGACA',\n",
       " 'AAACAAACAA',\n",
       " 'NNNNNNNAAA',\n",
       " 'AAACAAACAC',\n",
       " 'NNNACCGAGA',\n",
       " 'AAAACCGAAA',\n",
       " 'NNNACAGACA',\n",
       " 'AAACAAGACA',\n",
       " 'AAACAACAAA',\n",
       " 'AAAACAGCAA',\n",
       " 'CGAAAGCAAC',\n",
       " 'NNNAACGAAA',\n",
       " 'AACAACGAAC',\n",
       " 'CAAACAGCAA',\n",
       " 'ACAAAAGACA',\n",
       " 'AAGACCAAAA',\n",
       " 'ACAAACGAAC',\n",
       " 'NNNNNNNCAA',\n",
       " 'NNNNNNNACA',\n",
       " 'AAAGCAACAA',\n",
       " 'NNGCCAGACA',\n",
       " 'AGAAACCAAA',\n",
       " 'NNNAGCAAAA',\n",
       " 'CCAAGCAAAA',\n",
       " 'AAAACAACAA',\n",
       " 'NNNNNNNNAC',\n",
       " 'CGGAACAGCA',\n",
       " 'NNNNNNNNNA',\n",
       " 'NNNCAACGAA',\n",
       " 'AACAACGAAA',\n",
       " 'CCAAAGACGA',\n",
       " 'NNNNCAGACA',\n",
       " 'NNNNNNNCAA',\n",
       " 'AAACAAGACA',\n",
       " 'ACAAGAAACC',\n",
       " 'AGACAGCAAC',\n",
       " 'AAACAACAAA',\n",
       " 'AGACACGAAA',\n",
       " 'AAACAAGACA',\n",
       " 'TGACAACAAA',\n",
       " 'NNNNGTAAAC',\n",
       " 'NNNNNNNATA',\n",
       " 'ACGACAGAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'ACAGACACGA',\n",
       " 'NNNNNNNNNA',\n",
       " 'AACAAACGAA',\n",
       " 'CAACAAGACA',\n",
       " 'GAAACACAGA',\n",
       " 'AAACAACAAA',\n",
       " 'NGCAACACAA',\n",
       " 'GAAAACAAAC',\n",
       " 'ACAAAACAAA',\n",
       " 'ACAAAAGACA',\n",
       " 'NNNNNNGAAA',\n",
       " 'NNNNNNNCAA',\n",
       " 'CCAAGCAGAA',\n",
       " 'NNNTCCAAAC',\n",
       " 'GACAAAAGAC',\n",
       " 'ACAAAAGACC',\n",
       " 'CCAAAACAAA',\n",
       " 'AAACAACAAA',\n",
       " 'CGCAAGAACC',\n",
       " 'CGGAACAAGC',\n",
       " 'NNNNNNACCA',\n",
       " 'AGAACAAGAC',\n",
       " 'NNNNNNNCAA',\n",
       " 'CACAAAGCAA',\n",
       " 'CAAGCACAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'NNGTAAGCAC',\n",
       " 'CACAAAGAAC',\n",
       " 'GCAAACCAAA',\n",
       " 'GGCAACACAA',\n",
       " 'AAAACAGCAC',\n",
       " 'GCAGAAAACA',\n",
       " 'NNNNNNGCCA',\n",
       " 'NNNNNNNACA',\n",
       " 'NNNNNNGACA',\n",
       " 'AACAGAAAAC',\n",
       " 'GACAAAACCA',\n",
       " 'NNNNNNNNNA',\n",
       " 'NNNTCAGCAA',\n",
       " 'AGCAACGAAA',\n",
       " 'AACAAAGCAA',\n",
       " 'AAACAACAAA',\n",
       " 'AAAACAAACC',\n",
       " 'CCAGACAAAA',\n",
       " 'AACGAACAAA',\n",
       " 'AGCAAACAAA',\n",
       " 'AAACAACAAA',\n",
       " 'NNNNNNNNNA',\n",
       " 'CAAACAGCAC',\n",
       " 'NNNNNNNACA',\n",
       " 'AACAAACAAA',\n",
       " 'AACAAACAAA',\n",
       " 'CAACAAGACA',\n",
       " 'TAAACAGCAA',\n",
       " 'AGCAAAGACC',\n",
       " 'NNNACAGACA',\n",
       " 'AAACAAGACA',\n",
       " 'CACAAAGCAA',\n",
       " 'AACAAACAAA',\n",
       " 'ACAAAAGACA',\n",
       " 'AACAAAGCAA',\n",
       " 'AGACAACAAA',\n",
       " 'AAAACAGACA',\n",
       " 'AGCAAAGCAA',\n",
       " 'AAACAAACAA',\n",
       " 'NNNNNNNACC',\n",
       " 'AAAACCGAAA',\n",
       " 'NNNCAAGACA',\n",
       " 'AACAAAGCAC',\n",
       " 'GCAAAGAACA',\n",
       " 'GACAACGAGA',\n",
       " 'GCAACACGAA',\n",
       " 'AACAGACAAA',\n",
       " 'NNNNNNNCAA',\n",
       " 'AAGCGACAAA',\n",
       " 'NNNACGAACC',\n",
       " 'AACAAAGACA',\n",
       " 'AAACAAGACA',\n",
       " 'AAACGAAACA',\n",
       " 'GCCAAACGAA',\n",
       " 'ACAACACGAA',\n",
       " 'CGAGAACAAC',\n",
       " 'NNNNNNNTAA',\n",
       " 'ACGGAAACAA',\n",
       " 'AAACAACAAA',\n",
       " 'ACAAAACAAA',\n",
       " 'AAACACGAAA',\n",
       " 'ACAAAAGACA',\n",
       " 'ACGGACAAAA',\n",
       " 'CGAACCGAAA',\n",
       " 'NNNNNNNAGA',\n",
       " 'CCAAGCAAAA',\n",
       " 'GCCAAGCAAA',\n",
       " 'AACAGCAAGC',\n",
       " 'GAAACGAACA',\n",
       " 'NNNNNNNTCA',\n",
       " 'CACAAACAAA',\n",
       " 'CGACAAGCAA',\n",
       " 'CCGAAACAAA',\n",
       " 'ACAAACAAAA',\n",
       " 'CCAAACGAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'AACAAAGACC',\n",
       " 'AAGACAGACA',\n",
       " 'GCCAAGCAGA',\n",
       " 'NNNNNNNGCA',\n",
       " 'AACAAAGACA',\n",
       " 'AAACAAGACC',\n",
       " 'ACAAACGAAA',\n",
       " 'CGAACAACAA',\n",
       " 'AACAAAGACA',\n",
       " 'NNNATAGACA',\n",
       " 'CACAACGAAA',\n",
       " 'AACAAAGACA',\n",
       " 'NNNNGCCAAA',\n",
       " 'AACGCAGAAC',\n",
       " 'AAACAAGACA',\n",
       " 'CAAACAGCAA',\n",
       " 'GAAACCAAAC',\n",
       " 'CCGAGCAGAA',\n",
       " 'ACAAAACAAA',\n",
       " 'AAACAAGACA',\n",
       " 'CCGAAACAAA',\n",
       " 'AGAACAGACA',\n",
       " 'CACGAAAACA',\n",
       " 'NNNNNNNTAA',\n",
       " 'AAACAACAAA',\n",
       " 'ACAAAAGCAA',\n",
       " 'AACAACGAAA',\n",
       " 'AACAAAGACA',\n",
       " 'CAACAACAAA',\n",
       " 'AAACACGAAA',\n",
       " 'CACAAACAAA',\n",
       " 'TGAGCCAAAA',\n",
       " 'CAAAAGCAAC',\n",
       " 'AAAACGAACC',\n",
       " 'NNNNGCCAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'AGACAACAAA',\n",
       " 'TAACAAGACC',\n",
       " 'NNNATAGACA',\n",
       " 'CAACAACAAA',\n",
       " 'AAAACAGACC',\n",
       " 'GAACGAACAC',\n",
       " 'CCAAAAGACA',\n",
       " 'NNNACACAAA',\n",
       " 'AAGCAAGCCA',\n",
       " 'AAAGACGAAC',\n",
       " 'NNNNNNGCCA',\n",
       " 'GCAAACAGAC',\n",
       " 'CGGACAAGAA',\n",
       " 'NNNNNNNNCT',\n",
       " 'ACAAGAAACA',\n",
       " 'NNNATAGACA',\n",
       " 'NNNACCGAAA',\n",
       " 'CGACAACAAA',\n",
       " 'GACGAACAGA',\n",
       " 'NNNNNNNCTA',\n",
       " 'AAACACGAGA',\n",
       " 'CAACACGAAA',\n",
       " 'CAAACCGAAA',\n",
       " 'CCAAAAGACC',\n",
       " 'AACAACGAAA',\n",
       " 'AGACAAGCAA',\n",
       " 'ACAAAACAAA',\n",
       " 'AAACAACAAA',\n",
       " 'TAAACCGAAA',\n",
       " 'AAACAACAAA',\n",
       " 'ACAAAACAAA',\n",
       " 'ACAAAACAAA',\n",
       " 'AGAAGCAAAC',\n",
       " 'NCAAGCAAAC',\n",
       " 'AAAGCAAACA',\n",
       " 'NNNNNNNACA',\n",
       " 'ACGAACAAAG',\n",
       " 'AGAACGAACC',\n",
       " 'AGCGAAAACC',\n",
       " 'NNNNNNNACA',\n",
       " 'ACGACACAAA',\n",
       " 'NNNNNNNAGA',\n",
       " 'NNNNGAAAAC',\n",
       " 'NNNNNNNTCC',\n",
       " 'NNNNNNNGAA',\n",
       " 'ACGAGCAAAC',\n",
       " 'AACGAAAACC',\n",
       " 'NNNCAAGCAA',\n",
       " 'NNNNNNNGTA',\n",
       " 'GTAACAAGAC',\n",
       " 'AAACACGAAA',\n",
       " 'NNNCAAGACA',\n",
       " 'CGAGCAGAAA',\n",
       " 'NNNNNNNTCA',\n",
       " 'AAACAACGAA',\n",
       " 'TAACAAGACA',\n",
       " 'NNNNNNNACA',\n",
       " 'GCAAACAGAC',\n",
       " 'AACAGCGAAA',\n",
       " 'NNNNNNNCAA',\n",
       " 'ACAAAAGACA',\n",
       " 'AAACAAGCAA',\n",
       " 'NNNAAACAAC',\n",
       " 'ACGAAAGACA',\n",
       " 'ACAAAAGCAC',\n",
       " 'NNNNNNNNNT',\n",
       " 'ACAAAACAAA',\n",
       " 'CCAAAAGCAA',\n",
       " 'CGACGCAGAA',\n",
       " 'AAACGAAGCA',\n",
       " 'AAAGCAAACC',\n",
       " 'AAGACCGGAA',\n",
       " 'AAAACACAAA',\n",
       " 'ACAAACGAAA',\n",
       " 'GACAGAAAAC',\n",
       " 'NNNNGCCAAA',\n",
       " 'AACAACGAAA',\n",
       " 'AAACAAGCAA',\n",
       " 'NNNCTACAAA',\n",
       " 'AAAACAGACA',\n",
       " 'AAACAAGACA',\n",
       " 'AAAGCAACAC',\n",
       " 'ACAAAAGACA',\n",
       " 'AAACAACAAA',\n",
       " 'NNNACACAAA',\n",
       " 'AACAAAGCAA',\n",
       " 'AACAAACAAA',\n",
       " 'NNNACAGACA',\n",
       " 'GCCAAGCAAA',\n",
       " 'NNNNAAAGAC',\n",
       " 'CGGAACAGCA',\n",
       " 'NNNNNNNCTA',\n",
       " 'ACAAAAGCAA',\n",
       " 'AAACAACAAA',\n",
       " 'NNNAGCAAAA',\n",
       " 'GAACGAAACA',\n",
       " 'AACAACAGAC',\n",
       " 'CAGAACAGCA',\n",
       " 'ACAAAACAAA',\n",
       " 'ACAAAAGACA',\n",
       " 'AACAAGAGCA',\n",
       " 'GCAAGCACAA',\n",
       " 'ACGAAACAAC',\n",
       " 'ACAGCAGAAC',\n",
       " 'CCAAAAGACC',\n",
       " 'CCGGACAAAA',\n",
       " 'CACAGAAACC',\n",
       " 'NNNNNNNACC',\n",
       " 'GCAAACGAAA',\n",
       " 'AGACAAGACC',\n",
       " 'NNNNNNNCTA',\n",
       " 'GACAGCAAAC',\n",
       " 'AACAAAGACA',\n",
       " 'AAACAAGACA',\n",
       " 'GCCAGAAAAC',\n",
       " 'AGAAAACGAA',\n",
       " 'NNNATAGACA',\n",
       " 'NNNATCGAAA',\n",
       " 'AAAACACAAA',\n",
       " 'AGAACAGCAA',\n",
       " 'AGAACAGAAA',\n",
       " 'CAAAGACACA',\n",
       " 'NNNNNNNACC',\n",
       " 'NNNNGACAAA',\n",
       " 'NNNCGACAAA',\n",
       " 'GCAAAGAACA',\n",
       " 'NNNNGACAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'NNNNNNNAAA',\n",
       " 'AGCGAAGCAA',\n",
       " 'NNNAAAGCAA',\n",
       " 'AAACAAGACA',\n",
       " 'NNNATCGAAA',\n",
       " 'CGACAAGACA',\n",
       " 'CAAAAGGCAC',\n",
       " 'CCAAAAGACA',\n",
       " 'CCAGACAAAA',\n",
       " 'GAACGACAAC',\n",
       " 'ACAAAAGACA',\n",
       " 'AAGACCGAGA',\n",
       " 'NNNNNNNCTA',\n",
       " 'NNNNNNNNGA',\n",
       " 'AAACAGAACC',\n",
       " 'NNNNNNNTCA',\n",
       " 'CGAGACGACA',\n",
       " 'NNNNNNNAAA',\n",
       " 'GCCAAGCAAA',\n",
       " 'GAACGAAAAC',\n",
       " 'AACAACGAAC',\n",
       " 'CAGCAAGAAC',\n",
       " 'ACGAGCAAAA',\n",
       " 'CCAGACAAAA',\n",
       " 'CAAGACGAAC',\n",
       " 'AAAGACGAAC',\n",
       " 'AACAAAGACA',\n",
       " 'NNNACCGAAA',\n",
       " 'AAAGACAAAC',\n",
       " 'AACACAGAAA',\n",
       " 'GACGAAAACA',\n",
       " 'AACAGAAAAC',\n",
       " 'ACAAAAGCAA',\n",
       " 'AACAAACAAA',\n",
       " 'NNNNNAGCAA',\n",
       " 'CGCAAAAGAC',\n",
       " 'NNNATAGACA',\n",
       " 'AGACAAGCAA',\n",
       " 'ACAAAACAAA',\n",
       " 'AAAACAGCAA',\n",
       " 'AACAAACAAA',\n",
       " 'AGAACCGAAA',\n",
       " 'AGCCAAGCAA',\n",
       " 'NNNNNNNNNC',\n",
       " 'CGAACAAGCA',\n",
       " 'AGAACGCAGC',\n",
       " 'CCAAACGAAA',\n",
       " 'CAAACAGCAA',\n",
       " 'AACGACAAAA',\n",
       " 'NNNNNNNAAA',\n",
       " 'AACAAGAAAC',\n",
       " 'NCAAAGCAAC',\n",
       " 'NNNNNNNCAA',\n",
       " 'ACAGAAAACC',\n",
       " 'CGACGCAAAA',\n",
       " 'AAACAAGACA',\n",
       " 'AGCAAACAAC',\n",
       " 'NNNNNAAGCA',\n",
       " 'CAAGAAACGA',\n",
       " 'GAACGGAAAC',\n",
       " 'AAAACAGACA',\n",
       " 'AAACACGAAA',\n",
       " 'CACAAAGACA',\n",
       " 'AAACAACAAA',\n",
       " 'GAACGAAAAC',\n",
       " 'NNNNNNNCTA',\n",
       " 'AACAGCGACA',\n",
       " 'NNNNNNNAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'GAACAGCAAA',\n",
       " 'ACAACACGAA',\n",
       " 'NNNNNNNCAA',\n",
       " 'GAAACGAACC',\n",
       " 'AACGAAACAA',\n",
       " 'ACAAAACAAA',\n",
       " 'AACAAAGCAA',\n",
       " 'NNNNNNNAAA',\n",
       " 'AAAACAGCAA',\n",
       " 'NNNNNNNCAA',\n",
       " 'ACAGAAACAA',\n",
       " 'CAAACACAAA',\n",
       " 'GCAAGAAACA',\n",
       " 'NNNCAACAAA',\n",
       " 'AAGCAAGCAA',\n",
       " 'GAAACAGACA',\n",
       " 'AACAAAGACA',\n",
       " 'AACAAAGCAA',\n",
       " 'AAAACAGACA',\n",
       " 'ACAAAAGACC',\n",
       " 'AACAAAGACA',\n",
       " 'AAAACAGCAA',\n",
       " 'CCAAAAGCAA',\n",
       " 'ACAAAAGACA',\n",
       " 'AAACAAGCAA',\n",
       " 'AACAAAGCAA',\n",
       " 'AAACAAGACA',\n",
       " 'NNNNNNGAAA',\n",
       " 'ACCAAGCAAA',\n",
       " 'AGAGCAAACA',\n",
       " 'NNNATAGACA',\n",
       " 'GACGAAAACA',\n",
       " 'NNNNNNNACA',\n",
       " 'AACAACGAAA',\n",
       " 'AGAACGAACA',\n",
       " 'ACAACAGAAC',\n",
       " 'AACGAAGAAC',\n",
       " 'AGCAAAGCAA',\n",
       " 'NNNNGCACAA',\n",
       " 'CCAAGCAGAA',\n",
       " 'NNNNNNNATG',\n",
       " 'CCAAACGAAA',\n",
       " 'AAACAACAAA',\n",
       " 'CGACAGACAA',\n",
       " 'NNNNNNNNNA',\n",
       " 'NNNGCCAAAC',\n",
       " 'ACAAACGAAA',\n",
       " 'AAAACAGACA',\n",
       " 'AAAACCGAAA',\n",
       " 'AAACAAGACA',\n",
       " 'GAACAAGACA',\n",
       " 'GCAACAAGCA',\n",
       " 'NNNNNNGCCA',\n",
       " 'ACCAAAACAA',\n",
       " 'NNNNNNGTAA',\n",
       " 'NNNNNNGCCA',\n",
       " 'GCAACAACAA',\n",
       " 'CCGAGCAAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'GCAAAGAGCA',\n",
       " 'AGACGCAAGC',\n",
       " 'GAAACCGAAA',\n",
       " 'AAACAAGACA',\n",
       " 'NNNNNNNCAA',\n",
       " 'AACAAGACAC',\n",
       " 'CAAGCACAAA',\n",
       " 'NNNNNNNACA',\n",
       " 'AGCAACAGCA',\n",
       " 'NNNCAAGACC',\n",
       " 'AAAGCAACAC',\n",
       " 'NNNNNNNTAA',\n",
       " 'NNNTAAGCAA',\n",
       " 'AAAACAGACA',\n",
       " 'ACAAAAGACA',\n",
       " 'AAACAACAAA',\n",
       " 'ACAAAACAAA',\n",
       " 'NNNCAAGACA',\n",
       " 'AAACAACAAA',\n",
       " 'CACAAAGACA',\n",
       " 'CACAACGAAA',\n",
       " 'ACAAAAGCAA',\n",
       " 'NNNAAAGACA',\n",
       " 'CGAACACAAC',\n",
       " 'AAACAAGACA',\n",
       " 'AACAAAGCAA',\n",
       " 'CCGAGCAAAA',\n",
       " 'NNNAGCAAAA',\n",
       " 'NNNGCAACAA',\n",
       " 'ACGGACAAAA',\n",
       " 'ACAAGAAGCA',\n",
       " 'ACAGCAAAAC',\n",
       " 'AAAACCGAAA',\n",
       " 'ACAAAAGACC',\n",
       " 'AGGCAACACA',\n",
       " 'GAAAACGAAC',\n",
       " 'GAAACAGACC',\n",
       " 'AAACAAGACA',\n",
       " 'AACAACGAAA',\n",
       " 'CAACAAGACA',\n",
       " 'CACGAACAAA',\n",
       " 'NNNNNNNAAA']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_subseqs_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
